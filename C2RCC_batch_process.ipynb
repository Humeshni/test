{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5f0a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime     # a libary that allows us to work with dates and times\n",
    "import json         # a library that helps us make JSON format files\n",
    "import numpy as np  # a library that lets us work with arrays; we import this with a new name \"np\"\n",
    "import os           # a library that allows us access to basic operating system commands like making directories\n",
    "from shapely import geometry # a library that support construction of geometry objects\n",
    "import shutil       # a library that allows us access to basic operating system commands like copy\n",
    "import xml.etree.ElementTree as ET # a library that allows us to work with XML files\n",
    "import zipfile      # a library that allows us to unzip zip-files.\n",
    "import eumdac       # a tool that helps us download via the eumetsat/data-store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a53ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = os.path.join(os.getcwd(), \"1b_products\")\n",
    "os.makedirs(download_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c17d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection ID(EO:EUM:DAT:0556): OLCI Level 2 Ocean Colour Full Resolution (version BC003) - Sentinel-3 - Reprocessed\n",
      "Collection ID(EO:EUM:DAT:0409): OLCI Level 1B Full Resolution - Sentinel-3\n",
      "Collection ID(EO:EUM:DAT:0407): OLCI Level 2 Ocean Colour Full Resolution - Sentinel-3\n",
      "Collection ID(EO:EUM:DAT:0577): OLCI Level 1B Full Resolution (version BC002) - Sentinel-3 - Reprocessed\n",
      "Collection ID(EO:EUM:DAT:0557): OLCI Level 2 Ocean Colour Reduced Resolution (version BC003) - Sentinel-3 - Reprocessed\n",
      "Collection ID(EO:EUM:DAT:0578): OLCI Level 1B Reduced Resolution (version BC002) - Sentinel-3 - Reprocessed\n",
      "Collection ID(EO:EUM:DAT:0593): OLCI Level 2 Ocean Colour Reduced Resolution (version BC002) - Sentinel-3 - Reprocessed\n",
      "Collection ID(EO:EUM:DAT:0592): OLCI Level 2 Ocean Colour Full Resolution (version BC002) - Sentinel-3 - Reprocessed\n",
      "Collection ID(EO:EUM:DAT:0410): OLCI Level 1B Reduced Resolution - Sentinel-3\n",
      "Collection ID(EO:EUM:DAT:0408): OLCI Level 2 Ocean Colour Reduced Resolution - Sentinel-3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load credentials\n",
    "token = eumdac.AccessToken(('4gg07oXRQsrNrwskG5DqVeFQXAoa', 'L6X0YjJFcnffd9rmLHc_ZtmXsqIa'))\n",
    "\n",
    "datastore = eumdac.DataStore(token)\n",
    "for collection_id in datastore.collections:\n",
    "    if \"OLCI\" in collection_id.title:\n",
    "        print(f\"Collection ID({collection_id}): {collection_id.title}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9e4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set collection ID for OLCI L1 EFR\n",
    "collectionID = 'EO:EUM:DAT:0409'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc548151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLCI Level 1B Full Resolution - Sentinel-3\n",
      "---\n",
      "OLCI (Ocean and Land Colour Instrument) Full resolution: 300m at nadir. Level 1 products are calibrated Top Of Atmosphere radiance values at OLCI 21 spectral bands. Radiances are computed from the instrument digital counts by applying geo-referencing, radiometric processing (non-linearity correction, smear correction, dark offset correction, absolute gain calibration adjusted for gain evolution with time), and stray-light correction for straylight effects in OLCI camera's spectrometer and ground imager. Additionally, spatial resampling of OLCI pixels to the 'ideal' instrument grid, initial pixel classification, and annotation at tie points with auxiliary meteorological data and acquisition geometry are provided. The radiance products are accompanied by error estimate products, however the error values are currently not available. - All Sentinel-3 NRT products are available at pick-up point in less than 3h. - All Sentinel-3 Non Time Critical (NTC) products are available at pick-up point in less than 30 days. Sentinel-3 is part of a series of Sentinel satellites, under the umbrella of the EU Copernicus programme.\n"
     ]
    }
   ],
   "source": [
    "# Use collection ID\n",
    "selected_collection = datastore.get_collection(collectionID)\n",
    "print(f\"{selected_collection.title}\\n---\\n{selected_collection.abstract}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3055201f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# time filter the collection for products\n",
    "dtstart = datetime.datetime(2022, 6, 24, 0, 0)\n",
    "dtend = datetime.datetime(2022, 6, 28, 23, 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ee7094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2311 products\n"
     ]
    }
   ],
   "source": [
    "products = selected_collection.search(dtstart=dtstart, dtend=dtend)\n",
    "print(f\"Found {len(products)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f857b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space/time filter the collection for products\n",
    "north = 58.50\n",
    "south = 53.75\n",
    "east = 21.80\n",
    "west = 17.50\n",
    "ROI = [[west, south], [east, south], [east, north], [west, north], [west, south]]\n",
    "ROI_WKT = geometry.Polygon([[p[0], p[1]] for p in ROI])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5943ec21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 products\n"
     ]
    }
   ],
   "source": [
    "products = selected_collection.search(\n",
    "    geo=ROI_WKT,\n",
    "    dtstart=dtstart, \n",
    "    dtend=dtend)\n",
    "print(f\"Found {len(products)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb66ba9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 products\n"
     ]
    }
   ],
   "source": [
    "products = selected_collection.search(\n",
    "    geo=ROI_WKT,\n",
    "    dtstart=dtstart, \n",
    "    dtend=dtend, \n",
    "    timeliness='NT')\n",
    "print(f\"Found {len(products)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7cce061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 products\n"
     ]
    }
   ],
   "source": [
    "products = selected_collection.search(\n",
    "    geo=ROI_WKT,\n",
    "    dtstart=dtstart, \n",
    "    dtend=dtend, \n",
    "    timeliness='NT',\n",
    "    sat=\"Sentinel-3A\")\n",
    "print(f\"Found {len(products)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f076c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 products\n"
     ]
    }
   ],
   "source": [
    "processed_list = []\n",
    "final_products = []\n",
    "for product in products:\n",
    "    file_tags = str(product).split('_')\n",
    "    file_tags = [i for i in file_tags if i]\n",
    "    granule_start = file_tags[4]\n",
    "    if granule_start not in processed_list:\n",
    "        final_products.append(product)\n",
    "        processed_list.append(granule_start)\n",
    "        \n",
    "print(f\"Found {len(final_products)} products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9541115",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_threshold = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2ad3ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage overlap: 100%, downloading product\n",
      "Downloading S3A_OL_1_EFR____20220628T085911_20220628T090211_20220629T160353_0180_087_050_1980_MAR_O_NT_002.SEN3.zip.\n",
      "Download of product S3A_OL_1_EFR____20220628T085911_20220628T090211_20220629T160353_0180_087_050_1980_MAR_O_NT_002.SEN3.zip finished.\n",
      "Unzipping of product C:\\Users\\27614\\Desktop\\Masters Thesis\\codes\\Untitled Folder\\1b_products\\S3A_OL_1_EFR____20220628T085911_20220628T090211_20220629T160353_0180_087_050_1980_MAR_O_NT_002.SEN3.zip finished.\n",
      "Percentage overlap: 100%, downloading product\n",
      "Downloading S3A_OL_1_EFR____20220627T092522_20220627T092822_20220630T140909_0179_087_036_1980_MAR_O_NT_002.SEN3.zip.\n",
      "Download of product S3A_OL_1_EFR____20220627T092522_20220627T092822_20220630T140909_0179_087_036_1980_MAR_O_NT_002.SEN3.zip finished.\n",
      "Unzipping of product C:\\Users\\27614\\Desktop\\Masters Thesis\\codes\\Untitled Folder\\1b_products\\S3A_OL_1_EFR____20220627T092522_20220627T092822_20220630T140909_0179_087_036_1980_MAR_O_NT_002.SEN3.zip finished.\n",
      "Percentage overlap: 71%, downloading product\n",
      "Downloading S3A_OL_1_EFR____20220626T095133_20220626T095433_20220627T152906_0179_087_022_1980_MAR_O_NT_002.SEN3.zip.\n"
     ]
    },
    {
     "ename": "ProtocolError",
     "evalue": "('Connection broken: IncompleteRead(420205 bytes read)', IncompleteRead(420205 bytes read))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\conda3\\lib\\http\\client.py:560\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_next_chunk_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\conda3\\lib\\http\\client.py:527\u001b[0m, in \u001b[0;36mHTTPResponse._read_next_chunk_size\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# close the connection as protocol synchronisation is\u001b[39;00m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;66;03m# probably lost\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 16: b''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\conda3\\lib\\http\\client.py:592\u001b[0m, in \u001b[0;36mHTTPResponse._readinto_chunked\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 592\u001b[0m     chunk_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_chunk_left\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    593\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\conda3\\lib\\http\\client.py:562\u001b[0m, in \u001b[0;36mHTTPResponse._get_chunk_left\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m--> 562\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunk_left \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    564\u001b[0m     \u001b[38;5;66;03m# last chunk: 1*(\"0\") [ chunk-extension ] CRLF\u001b[39;00m\n",
      "\u001b[1;31mIncompleteRead\u001b[0m: IncompleteRead(0 bytes read)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIncompleteRead\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\conda3\\lib\\site-packages\\urllib3\\response.py:441\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\conda3\\lib\\site-packages\\urllib3\\response.py:522\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    521\u001b[0m cache_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 522\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    524\u001b[0m     amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data\n\u001b[0;32m    525\u001b[0m ):  \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\conda3\\lib\\http\\client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 463\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n",
      "File \u001b[1;32m~\\Documents\\conda3\\lib\\http\\client.py:497\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[1;32m--> 497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readinto_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\conda3\\lib\\http\\client.py:608\u001b[0m, in \u001b[0;36mHTTPResponse._readinto_chunked\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m IncompleteRead:\n\u001b[1;32m--> 608\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;28mbytes\u001b[39m(b[\u001b[38;5;241m0\u001b[39m:total_bytes]))\n",
      "\u001b[1;31mIncompleteRead\u001b[0m: IncompleteRead(420205 bytes read)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m final_product\u001b[38;5;241m.\u001b[39mopen() \u001b[38;5;28;01mas\u001b[39;00m fsrc, \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_dir, fsrc\u001b[38;5;241m.\u001b[39mname), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfsrc\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfileobj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfsrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfdst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDownload of product \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfsrc\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m finished.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# unzip the file\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\conda3\\lib\\shutil.py:205\u001b[0m, in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    203\u001b[0m fdst_write \u001b[38;5;241m=\u001b[39m fdst\u001b[38;5;241m.\u001b[39mwrite\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m     buf \u001b[38;5;241m=\u001b[39m \u001b[43mfsrc_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m buf:\n\u001b[0;32m    207\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\conda3\\lib\\site-packages\\urllib3\\response.py:544\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    534\u001b[0m             flush_decoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    535\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menforce_content_length \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_remaining \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[0;32m    536\u001b[0m                 \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m    537\u001b[0m                 \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[38;5;66;03m# raised during streaming, so all calls with incorrect\u001b[39;00m\n\u001b[0;32m    543\u001b[0m                 \u001b[38;5;66;03m# Content-Length are caught.\u001b[39;00m\n\u001b[1;32m--> 544\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_bytes_read, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength_remaining)\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m    547\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp_bytes_read \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[1;32m~\\Documents\\conda3\\lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    135\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[1;32m~\\Documents\\conda3\\lib\\site-packages\\urllib3\\response.py:458\u001b[0m, in \u001b[0;36mHTTPResponse._error_catcher\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead timed out.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (HTTPException, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;66;03m# This includes IncompleteRead.\u001b[39;00m\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection broken: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e, e)\n\u001b[0;32m    460\u001b[0m \u001b[38;5;66;03m# If no exception is thrown, we should avoid cleaning up\u001b[39;00m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;66;03m# unnecessarily.\u001b[39;00m\n\u001b[0;32m    462\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection broken: IncompleteRead(420205 bytes read)', IncompleteRead(420205 bytes read))"
     ]
    }
   ],
   "source": [
    "# 1. set up the product loop\n",
    "for final_product in final_products:\n",
    "    \n",
    "    # 2. this reads the XML into memory and finds the correct part for the polygon and compares against our reference\n",
    "    for entry in final_product.entries:\n",
    "        if 'xfdumanifest.xml' in entry:\n",
    "            with final_product.open(entry=entry) as fsrc:\n",
    "                tree = ET.ElementTree(ET.fromstring(fsrc.data))\n",
    "                root = tree.getroot()\n",
    "                polygon = np.asarray(root.findall('.//gml:posList',\n",
    "                    {'gml':\"http://www.opengis.net/gml\"})[0].text.split(' ')).astype(float)\n",
    "                this_polygon = geometry.Polygon(list(zip(polygon[1::2], polygon[0::2])))\n",
    "                pc_overlap = ROI_WKT.intersection(this_polygon).area/ROI_WKT.area*100\n",
    "\n",
    "    # 3. if our overlap is greater than the threshold, we get the download the data and unzip it\n",
    "    if pc_overlap > overlap_threshold:\n",
    "        print(f\"Percentage overlap: {int(pc_overlap)}%, downloading product\")\n",
    "\n",
    "        # download the zip file\n",
    "        with final_product.open() as fsrc, open(os.path.join(download_dir, fsrc.name), mode='wb') as fdst:\n",
    "            print(f'Downloading {fsrc.name}.')\n",
    "            shutil.copyfileobj(fsrc, fdst)\n",
    "            print(f'Download of product {fsrc.name} finished.')\n",
    "\n",
    "        # unzip the file\n",
    "        with zipfile.ZipFile(fdst.name, 'r') as zip_ref:\n",
    "            for file in zip_ref.namelist():\n",
    "                if file.startswith(str(final_product)):\n",
    "                    zip_ref.extract(file, download_dir)\n",
    "            print(f'Unzipping of product {fdst.name} finished.')\n",
    "\n",
    "        # clean up\n",
    "        os.remove(fdst.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c556970",
   "metadata": {},
   "source": [
    "## SNAP batch processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b62a8930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os           # a library that allows us access to basic operating system commands like making directories\n",
    "import shutil       # a library that allows us access to basic operating system commands like copy\n",
    "import subprocess   # a library that lets us call external processes\n",
    "import fnmatch      # a library that supports comparing files to a specified pattern\n",
    "import platform     # a library that determines the current operating system\n",
    "from shapely import geometry # a library that support construction of geometry objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "311bb0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(os.getcwd(), \"c2rcc_outputs\")\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb2e7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_xml = 'GPT_config_template.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa5bd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.path.join(os.getcwd(),'1b_products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b39199dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\27614\\Desktop\\Masters Thesis\\codes\\Untitled Folder\\1b_products\\S3A_OL_1_EFR____20220627T092522_20220627T092822_20220630T140909_0179_087_036_1980_MAR_O_NT_002.SEN3\\xfdumanifest.xml\n",
      "C:\\Users\\27614\\Desktop\\Masters Thesis\\codes\\Untitled Folder\\1b_products\\S3A_OL_1_EFR____20220628T085911_20220628T090211_20220629T160353_0180_087_050_1980_MAR_O_NT_002.SEN3\\xfdumanifest.xml\n"
     ]
    }
   ],
   "source": [
    " # make a list of all the input files in your input directory\n",
    "input_files=[]\n",
    "for root, _, filenames in os.walk(input_dir):\n",
    "    for filename in fnmatch.filter(filenames, '*xfdumanifest.xml'):\n",
    "        if \"EFR\" in root:\n",
    "            input_files.append(os.path.join(root, filename))\n",
    "\n",
    "# and show the list        \n",
    "for input_file in input_files:\n",
    "    print(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ad324ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This platform is: windows\n",
      "The default path is C:/Program Files\\snap\\bin\\gpt.exe, please adapt the GPT_PATH variable if this is not correct\n"
     ]
    }
   ],
   "source": [
    "print(f\"This platform is: {platform.system().lower()}\")\n",
    "if platform.system().lower() == \"darwin\":\n",
    "    GPT_PATH = os.path.join(\"/\", \"Applications\", \"snap\", \"bin\", \"gpt\")\n",
    "elif platform.system().lower() == \"windows\":\n",
    "    GPT_PATH = os.path.join(\"C:/\", \"Program Files\", \"snap\", \"bin\", \"gpt.exe\")\n",
    "print(f\"The default path is {GPT_PATH}, please adapt the GPT_PATH variable if this is not correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ecd9baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set geo_region to subset\n",
    "# space/time filter the collection for products\n",
    "north = 59.25\n",
    "west = 18.50\n",
    "south = 56.75\n",
    "east = 21.50\n",
    "\n",
    "ROI = [[west, south], [east, south], [east, north], [west, north], [west, south]]\n",
    "ROI_polygon = geometry.Polygon([[p[0], p[1]] for p in ROI])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1dc99283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------- Processing: --------------\n",
      "C:\\Users\\27614\\Desktop\\Masters Thesis\\codes\\Untitled Folder\\1b_products\\S3A_OL_1_EFR____20220627T092522_20220627T092822_20220630T140909_0179_087_036_1980_MAR_O_NT_002.SEN3\\xfdumanifest.xml\n",
      "-- To: --\n",
      "S3A_OL_1_EFR____20220627T092522_20220627T092822_20220630T140909_0179_087_036_1980_MAR_O_NT_002_SUBSET_IDEPIX_C2RCC.nc\n",
      "-- Generating config: --\n",
      "C:\\Users\\27614\\Desktop\\Masters Thesis\\codes\\Untitled Folder\\c2rcc_outputs\\run_config.xml\n",
      "-- Config ready; running: --\n",
      "C:/Program Files\\snap\\bin\\gpt.exe C:\\Users\\27614\\Desktop\\Masters Thesis\\codes\\Untitled Folder\\c2rcc_outputs\\run_config.xml\n",
      "----- Finished running this product -----\n",
      "\n",
      "-------------- Processing: --------------\n",
      "C:\\Users\\27614\\Desktop\\Masters Thesis\\codes\\Untitled Folder\\1b_products\\S3A_OL_1_EFR____20220628T085911_20220628T090211_20220629T160353_0180_087_050_1980_MAR_O_NT_002.SEN3\\xfdumanifest.xml\n",
      "-- To: --\n",
      "S3A_OL_1_EFR____20220628T085911_20220628T090211_20220629T160353_0180_087_050_1980_MAR_O_NT_002_SUBSET_IDEPIX_C2RCC.nc\n",
      "-- Generating config: --\n",
      "C:\\Users\\27614\\Desktop\\Masters Thesis\\codes\\Untitled Folder\\c2rcc_outputs\\run_config.xml\n",
      "-- Config ready; running: --\n",
      "C:/Program Files\\snap\\bin\\gpt.exe C:\\Users\\27614\\Desktop\\Masters Thesis\\codes\\Untitled Folder\\c2rcc_outputs\\run_config.xml\n",
      "----- Finished running this product -----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MAIN: the loop goes over each input file in the input_files list\n",
    "for input_file in input_files:\n",
    "\n",
    "    # 1. define an output file name. This is derived from the input file, but with a _SUBSET_IDEPIX_C2RCC suffix.\n",
    "    output_file = input_file.replace(input_dir,output_dir)\n",
    "    output_file = os.path.dirname(output_file).replace('.SEN3','_SUBSET_IDEPIX_C2RCC.nc')\n",
    "    print(f\"-------------- Processing: --------------\\n{input_file}\")\n",
    "    print(f\"-- To: --\\n{os.path.basename(output_file)}\")\n",
    "    \n",
    "    # 2. read the template xml and adapt it for the current granule\n",
    "    my_config = os.path.join(output_dir, 'run_config.xml')\n",
    "    print(f\"-- Generating config: --\\n{my_config}\")\n",
    "    shutil.copy(template_xml, my_config)\n",
    "\n",
    "    with open(template_xml, 'r') as file:\n",
    "        filedata = file.read()\n",
    "        \n",
    "    # Replace the target strings\n",
    "    filedata = filedata.replace('SOURCE_PRODUCT', input_file)\n",
    "    filedata = filedata.replace('OUTPUT_PRODUCT', output_file)\n",
    "    filedata = filedata.replace('GEO_REGION', str(ROI_polygon))\n",
    "\n",
    "    # Write the file out again\n",
    "    with open(my_config, 'w') as file:\n",
    "        file.write(filedata)\n",
    "\n",
    "    # 3. the processing call is a follows below.\n",
    "    c2rcc_processing_call = GPT_PATH + ' ' + my_config\n",
    "    \n",
    "    # It is useful to check that the command call is correct before launching the call\n",
    "    print(f\"-- Config ready; running: --\\n{c2rcc_processing_call}\")\n",
    "    \n",
    "    # Run the gpt command\n",
    "    process = subprocess.Popen(c2rcc_processing_call, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    output, err = process.communicate()\n",
    "\n",
    "    print(f\"----- Finished running this product -----\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0910bf0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
